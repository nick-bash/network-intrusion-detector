{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "76dfbd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "import time\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9daff483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD FILES\n",
    "\n",
    "# prefix string with r to avoid unicode escape on '\\U'\n",
    "path = r'C:\\Users\\Nick Bashour\\Documents\\Personal\\14. Stanford\\2. Academics\\3. 2021 Spring\\1. CS 230\\2. Project\\2. Data\\MachineLearningCVE\\\\'\n",
    "files = [\n",
    "    'Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv',\n",
    "    'Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv',\n",
    "    'Friday-WorkingHours-Morning.pcap_ISCX.csv',\n",
    "    'Monday-WorkingHours.pcap_ISCX.csv',\n",
    "    'Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv',\n",
    "    'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv',\n",
    "    'Tuesday-WorkingHours.pcap_ISCX.csv',\n",
    "    'Wednesday-workingHours.pcap_ISCX.csv'\n",
    "]\n",
    "\n",
    "for i in range(len(files)):    \n",
    "    files[i] = path + files[i]\n",
    "\n",
    "pd_files = [pd.read_csv(f) for f in files]\n",
    "df = pd.concat(pd_files)\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e084d6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BENIGN', 'DDoS', 'PortScan', 'Bot', 'Infiltration',\n",
       "       'Web Attack - Brute Force', 'Web Attack - XSS',\n",
       "       'Web Attack - Sql Injection', 'FTP-Patator', 'SSH-Patator',\n",
       "       'DoS slowloris', 'DoS Slowhttptest', 'DoS Hulk', 'DoS GoldenEye',\n",
       "       'Heartbleed'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df['Label'].unique()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5d1ae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 395.6536331176758\n"
     ]
    }
   ],
   "source": [
    "# RANDOMLY SORT & VECTORIZE DATA. SPLIT INTO TEST / TRAIN, AND NORMALIZE ACCORDING TO MEAN / STD OF TRAIN.\n",
    "# Note: due to compute constraints, for the project milestone I am only processing data for the \n",
    "#       first of 8 files within the data set.\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "# Random sort\n",
    "data = pd_files[0].sample(frac=1)\n",
    "\n",
    "# dimensions\n",
    "m = len(data)\n",
    "nx = len(data.columns)-1\n",
    "ny = len(labels)\n",
    "m_test = 10000\n",
    "m_train = m - m_test\n",
    "\n",
    "# blank arrays\n",
    "X_train = np.zeros((nx, m_train))\n",
    "Y_train = np.zeros((ny, m_train))\n",
    "X_test = np.zeros((nx, m_test))\n",
    "Y_test = np.zeros((ny, m_test))\n",
    "\n",
    "# Convert labels into a one hot vector\n",
    "def one_hot(label):    \n",
    "    return np.where(labels == label, 1, 0)\n",
    "\n",
    "# Vectorize training set\n",
    "for j in range(m_train):\n",
    "    for i in range(nx):\n",
    "        X_train[i,j] = data.iloc[j,i]\n",
    "    Y_train[:,j] = one_hot(str(data.iloc[j,len(data.columns)-1]))\n",
    "    \n",
    "# Vectorize test set\n",
    "for j in range(m_test):\n",
    "    for i in range(nx):\n",
    "        X_test[i,j] = data.iloc[j+m_train,i]\n",
    "    Y_test[:,j] = one_hot(str(data.iloc[j+m_train,len(data.columns)-1]))\n",
    "    \n",
    "toc = time.time()\n",
    "print(\"time elapsed: \" + str(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d786d70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for Nan's and replace with 0's\n",
    "# print(np.count_nonzero(np.isnan(X_train)))\n",
    "# X_train[np.isnan(X_train)] = 0\n",
    "# print(np.count_nonzero(np.isnan(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c4a3b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-05765efc8020>:8: RuntimeWarning: invalid value encountered in subtract\n",
      "  X_train = (X_train - mean)/std\n",
      "<ipython-input-50-05765efc8020>:9: RuntimeWarning: invalid value encountered in subtract\n",
      "  X_test = (X_test - mean)/std\n"
     ]
    }
   ],
   "source": [
    "# Normalize training & test sets according to training set data\n",
    "mean = np.mean(X_train, axis=1)\n",
    "epsilon = pow(10,-7)\n",
    "std = np.std(X_train, axis=1) + epsilon\n",
    "mean = mean.reshape(mean.shape[0],1)\n",
    "std = std.reshape(std.shape[0],1)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f9f1041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for Nan's and replace with 0's\n",
    "# print(np.count_nonzero(np.isnan(X_test)))\n",
    "# X_test[np.isnan(X_test)] = 0\n",
    "# print(np.count_nonzero(np.isnan(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3336571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write files to CSV\n",
    "\n",
    "out_X_train = open(\"out_X_train.csv\", \"w\")\n",
    "np.savetxt('out_X_train.csv', X_train, delimiter=',')\n",
    "out_Y_train = open(\"out_Y_train.csv\", \"w\")\n",
    "np.savetxt('out_Y_train.csv', Y_train, delimiter=',')\n",
    "\n",
    "out_X_test = open(\"out_X_test.csv\", \"w\")\n",
    "np.savetxt('out_X_test.csv', X_test, delimiter=',')\n",
    "out_Y_test = open(\"out_Y_test.csv\", \"w\")\n",
    "np.savetxt('out_Y_test.csv', Y_test, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
