{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "87d58a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b62c13ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 31.45568823814392 sec's\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "tic = time.time()\n",
    "\n",
    "path = r'C:\\Users\\Nick Bashour\\Documents\\Personal\\14. Stanford\\2. Academics\\3. 2021 Spring\\1. CS 230\\2. Project\\3. Code\\\\'\n",
    "X_train = np.genfromtxt(str(path+'out_X_train.csv'), delimiter=',')\n",
    "Y_train = np.genfromtxt(str(path+'out_Y_train.csv'), delimiter=',')\n",
    "\n",
    "X_test = np.genfromtxt(str(path+'out_X_test.csv'), delimiter=',')\n",
    "Y_test = np.genfromtxt(str(path+'out_Y_test.csv'), delimiter=',')\n",
    "\n",
    "toc = time.time()\n",
    "print(\"time elapsed: \" + str(toc-tic) + \" sec's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "053e5463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels\n",
    "labels = np.array(['BENIGN', 'DDoS', 'PortScan', 'Bot', 'Infiltration',\n",
    "       'Web Attack - Brute Force', 'Web Attack - XSS',\n",
    "       'Web Attack - Sql Injection', 'FTP-Patator', 'SSH-Patator',\n",
    "       'DoS slowloris', 'DoS Slowhttptest', 'DoS Hulk', 'DoS GoldenEye',\n",
    "       'Heartbleed'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4032e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "  \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of input vector\n",
    "    n_y -- scalar, number of classes\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"tf.float32\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"tf.float32\"    \n",
    "    \"\"\"\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[n_x,None], name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32, shape=[n_y,None], name=\"Y\")\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b82c7524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(L, param_sizes):\n",
    "    \"\"\"\n",
    "    Initializes weight parameters 'W' using Xavier Initialization and bias parameters 'b' to zero.\n",
    "    \n",
    "    Arguments:\n",
    "    L           -- the depth of the network\n",
    "    param_sizes -- a dictionary of shapes for every parameter matrix W and b of every layer L\n",
    "    \n",
    "    Returns:\n",
    "    parameters  -- a dictionary of tensors containing the initialized parameters\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    \n",
    "    for i in range(L):\n",
    "        W_curr = \"W\"+str(i+1)\n",
    "        b_curr = \"b\"+str(i+1)\n",
    "        parameters[W_curr] = tf.Variable(initial_value = np.random.randn(param_sizes[W_curr][0],param_sizes[W_curr][1])*0.01, name=W_curr, dtype=tf.float32, shape=param_sizes[W_curr])\n",
    "        parameters[b_curr] = tf.Variable(initial_value = np.zeros(param_sizes[b_curr]), name=b_curr, dtype=tf.float32, shape=param_sizes[b_curr])\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1fce0f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, L, params):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a model with L-1 hidden ReLU layers and a Softmax in the last layer\n",
    "    \n",
    "    Arguments:    \n",
    "    X      -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    L      -- total layers in the neural net\n",
    "    params -- python dictionary containing W and b parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last linear unit (does not calculate Softmax)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize activations to X and calculate\n",
    "    a_curr = X\n",
    "    l = 1\n",
    "    while l <= L:\n",
    "        w_curr = \"W\" + str(l)\n",
    "        b_curr = \"b\" + str(l)\n",
    "        z_curr = tf.add(tf.matmul(params[w_curr],a_curr), params[b_curr])        \n",
    "        if(l < L):\n",
    "                a_curr = tf.nn.relu(z_curr)\n",
    "        l += 1\n",
    "    \n",
    "    # Return the output of the last linear unit\n",
    "    return z_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b49661a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z_final, Y):\n",
    "    \"\"\"\n",
    "    Computes the softmax cross entropy cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z_final -- output of forward propagation (output of the last linear unit), of shape (# classes, # samples)\n",
    "    Y       -- \"true\" labels vector placeholder, same shape as Z_final\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # transpose to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z_final)\n",
    "    labels = tf.transpose(Y)    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "        \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3085b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, L, param_sizes, learning_rate = 0.0001,\n",
    "          num_epochs = 500, minibatch_size = 128, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements an L-layer tensorflow neural network where the first (L-1) layers are (Linear->ReLU)\n",
    "    and the final layer is a (Linear->Softmax)\n",
    "    \n",
    "    Arguments:\n",
    "    X_train        -- training set, of shape (# of features, training samples)\n",
    "    Y_train        -- test set, of shape (# of classes, training samples)\n",
    "    X_test         -- training set, of shape (# of features, test samples)\n",
    "    Y_test         -- test set, of shape (# of classes, test samples)\n",
    "    L              -- number of layers in the network\n",
    "    param_sizes    -- dictionary of matrix shapes for all parameters W and b, with keys \"W1\", \"b1\", etc.\n",
    "    learning_rate  -- learning rate of the optimization, default to 0.0001\n",
    "    num_epochs     -- number of epochs of the optimization loop, default to 500\n",
    "    minibatch_size -- size of a minibatch, default to 128\n",
    "    print_cost     -- boolean to print the cost every 100 epochs, default to True\n",
    "    \n",
    "    Returns:\n",
    "    params -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                            # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    params = initialize_parameters(L, param_sizes)\n",
    "    Z_final = forward_propagation(X, L, params)\n",
    "    cost = compute_cost(Z_final, Y)\n",
    "    # AdamOptimizer for gradient descent\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "        \n",
    "    # Initialize the session\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Run the training loop across epochs\n",
    "    with tf.Session() as sess:      \n",
    "        \n",
    "        sess.run(init)        \n",
    "        tic = time.time()\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0.                       \n",
    "            num_minibatches = int(m / minibatch_size) \n",
    "            \n",
    "            for i in range(num_minibatches):\n",
    "                \n",
    "                minibatch_X = X_train[:,minibatch_size*(i-1):minibatch_size*i]\n",
    "                minibatch_Y = Y_train[:,minibatch_size*(i-1):minibatch_size*i]             \n",
    "                _ , minibatch_cost = sess.run([optimizer,cost], feed_dict = {X: minibatch_X, Y: minibatch_Y})                                \n",
    "                epoch_cost += minibatch_cost / minibatch_size\n",
    "\n",
    "            # Print the cost and time elapsed every 100 epochs, store it every 5\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                toc = time.time()\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "                print (\"Time elapsed: \" + str(int(toc-tic)) + \" seconds\")\n",
    "                tic = time.time()\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('epochs (per fives)')\n",
    "        plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        params = sess.run(params)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z_final), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8b36216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: nan\n",
      "Time elapsed: 0 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.99972653\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ------------ MODEL TRAINING -----------------------------------\n",
    "L = 5\n",
    "(nx, m) = X_train.shape\n",
    "ny = Y_train.shape[0]\n",
    "param_sizes = {\n",
    "    \"W1\": (30,nx),\n",
    "    \"b1\": (30,1),\n",
    "    \"W2\": (24,30),\n",
    "    \"b2\": (24,1),\n",
    "    \"W3\": (16,24),\n",
    "    \"b3\": (16,1),\n",
    "    \"W4\": (10,16),\n",
    "    \"b4\": (10,1),\n",
    "    \"W5\": (ny,10),\n",
    "    \"b5\": (ny,1),\n",
    "}\n",
    "\n",
    "parameters = model(X_train, Y_train, X_test, Y_test, L, param_sizes, num_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "412a3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ TESTING /DEBUGGING -----------------------------------\n",
    "# -------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# ------------ Individual functions ---------------------------------\n",
    "# L = 2\n",
    "# param_sizes = {}\n",
    "# param_sizes[\"W1\"] = (4,3)\n",
    "# param_sizes[\"b1\"] = (4,1)\n",
    "# param_sizes[\"W2\"] = (5,4)\n",
    "# param_sizes[\"b2\"] = (5,1)\n",
    "# parameters = initialize_parameters(L, param_sizes)\n",
    "# X = np.random.randn(3,5)\n",
    "# Y = np.random.randn(5,5)\n",
    "# Z2 = forward_propagation(X, L, parameters)\n",
    "# cost = compute_cost(Z2, Y)\n",
    "# print(cost)\n",
    "\n",
    "# ------------ Entire model -----------------------------------------\n",
    "# L = 4\n",
    "# X_train_0 = np.random.randn(3,5)\n",
    "# Y_train_0 = np.random.randn(4,5)\n",
    "# X_test_0 = np.random.randn(3,2)\n",
    "# Y_test_0 = np.random.randn(4,2)\n",
    "\n",
    "# param_sizes = {\n",
    "#     \"W1\": (4,3),\n",
    "#     \"b1\": (4,1),\n",
    "#     \"W2\": (5,4),\n",
    "#     \"b2\": (5,1),\n",
    "#     \"W3\": (3,5),\n",
    "#     \"b3\": (3,1),\n",
    "#     \"W4\": (4,3),\n",
    "#     \"b4\": (4,1),\n",
    "# }\n",
    "\n",
    "# parameters = model(X_train_0, Y_train_0, X_test_0, Y_test_0, L, param_sizes, num_epochs = 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
